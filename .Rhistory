pi
t = seq((-2*pi),(2*pi),0.1)
y  =exp(-abs(x))sin(x)
y  =exp(-abs(x))sin(x)
y  =exp(-abs(x))*sin(x)
y  =exp(-abs(t))*sin(t)
plot(y,t)
plot(t,y)
t = seq((-2*pi),(2*pi),0.001)
y  =exp(-abs(t))*sin(t)
plot(t,y)
install.packages("igraph")
g = function(x,y,z)
{ p = x*y*z
p}
g(10.20.30)
g(10,20,30)
g = function(x,y,z){ p = x*y*z p}
g = function(x,y,z){ p = x*y*z, p}
g = function(x,y,z){ p = x*y*z
p}
g(10,20,30)
install.packages("sqldf")
library("matrixStats")
library("corrplot")
data = read.csv("red-wine.csv")
######################   Visualization    ####################################################
head(data)
tail(data)
corrplot(cor(data))
pairs(data)
hist(data$quality, col="red")
for (i in 1:11)
plot(quality ~ data[,i], xlab=colnames(data)[i], data = data)
##All pairwise corelation coefficients are less then 0.95
#looking at the pairs plot, it seems that linear regression is a resonable choice.
######################    Linear Regression    #################################################
l_r_model = lm(quality ~ . , data = data)
summary(l_r_model)
predicted.values = l_r_model$fitted.values
observed.value   = data[,12]
train.rmse    = sqrt(   mean( (observed.value - predicted.values)^2 )   )
train.rmse
######################   Cross Validation   ###############################################
no.of.folds = 10
index.values = sample(1:no.of.folds, size = dim(data)[1], replace = TRUE)
head(index.values)
table(index.values)/dim(data)[1]
test.mse = rep(0, no.of.folds)
for (i in 1:no.of.folds)
{
index.out            = which(index.values == i)
left.out.data        = data[  index.out, ]
left.in.data         = data[ -index.out, ]
tmp.lm               = lm(quality ~ ., data = left.in.data)
tmp.predicted.values = predict(tmp.lm, newdata = left.out.data)
test.mse[i]          = mean((left.out.data[,12] - tmp.predicted.values)^2)
}
test.mse
test.rmse = sqrt(mean(test.mse))
test.rmse
#############################################################################################
##########         Feature Selection Models        #########################################
############################################################################################
train_rows = 5000
test_rows = 2500
ped
ped
pwd
cwd
getwd()
setwd(C:/Users/ashut/Desktop/work'/Introduction to statistical Learning/Group Projects/Handwritten digit recognisition)
setwd("C:/Users/ashut/Desktop/work'/Introduction to statistical Learning/Group Projects/Handwritten digit recognisition")
getwd()
train_rows = 5000
test_rows = 2500
train = read.csv("train.csv" , header = F , nrows = train_rows )
test = read.csv( " test.csv " , header = F , nrow= test_rows )
train_rows = 5000
test_rows = 2500
train = read.csv("train.csv" , header = F , nrows = train_rows )
test = read.csv( "test.csv" , header = F , nrow= test_rows )
summary(train)
train[1]
train[:,1]
train[1,]
image(train[1,])
image(matrix(train[1,])
)
a = matrix(train[1,])
image(a)
28*28
length(train[1,])
length(train[1,-1])
train[1,-1]
train[1,1:784]
?matrix
a = matrix(train[1,1:784])
dim(a)
a = matrix(train[1,1:784], nrow = 28, ncol =28)
a
image(a)
image2Grid(a)
type(a)
summary(a)
class(a)
image(a)
a = as.array(train[1,1:784], nrow = 28, ncol =28)
?as.array
a = as.array(train[1,1:784])
error_rate_final
train_rows = 5000
test_rows = 2500
train = read.csv("train.csv" , header = F , nrows = train_rows )
test = read.csv( " test.csv " , header = F , nrow= test_rows )
#last column is the label
train$V785 = as.factor(train$V785 )
test$V785 = as.factor(test$V785 )
# remove predictors wth little variability
SD<20 # this parameter was set by tuning on the training set.
# ##
# ## 20 was s o r t o f a g u e s s !
# ##
cut_off = 20
bad_columns = which ( apply( train[ , - ncol( train ) ] , 2 , sd ) < cut_off )
length( bad_columns )
train = train[ ,-bad_columns ]
test = test[,-bad_columns]
# Train and test with SVM
library(e1071)
# tune
set.seed(110)
system.time ( {
tune_svm = tune( svm , V785 ~ . , data = train , kernel = " polynomial " , degree =3 ,
ranges = list ( cost = c(1,5,10,1000 ) , gamma = c(0.0001, 0.001,0.01,1)),
tunecontrol = tune.control(cross=5))
} )
tune_svm
# Create Final Model withh parameters
svm_final = svm( V785 ~ . , data = train , cost = tune_svm$best.parameters$cost , kernel = "polynomial " , degree =3 ,
gamma = tune_svm$best.parameters$gamma)
svm_y_final = predict( svm_final , newdata = test )
confusion_matrix_final = table( predicted = svm_y_final , actual = test$V785 )
confusion_matrix_final
error_rate_final = 1 - (sum(diag(confusion_matrix_final ) ) / nrow(test) )
error_rate_final
train_rows = 5000
test_rows = 2500
train = read.csv("train.csv" , header = F , nrows = train_rows )
test = read.csv( " test.csv " , header = F , nrow= test_rows )
#last column is the label
train$V785 = as.factor(train$V785 )
test$V785 = as.factor(test$V785 )
# remove predictors wth little variability
SD<20 # this parameter was set by tuning on the training set.
# ##
# ## 20 was s o r t o f a g u e s s !
# ##
cut_off = 20
bad_columns = which ( apply( train[ , - ncol( train ) ] , 2 , sd ) < cut_off )
length( bad_columns )
train = train[ ,-bad_columns ]
test = test[,-bad_columns]
# Train and test with SVM
library(e1071)
# tune
set.seed(110)
system.time ( {
tune_svm = tune( svm , V785 ~ . , data = train , kernel = " polynomial " , degree =3 ,
ranges = list ( cost = c(1,5,10,1000 ) , gamma = c(0.0001, 0.001,0.01,1)),
tunecontrol = tune.control(cross=5))
} )
tune_svm
# Create Final Model withh parameters
svm_final = svm( V785 ~ . , data = train , cost = tune_svm$best.parameters$cost , kernel = "polynomial " , degree =3 ,
gamma = tune_svm$best.parameters$gamma)
svm_y_final = predict( svm_final , newdata = test )
install.packages("e1071")
train_rows = 5000
test_rows = 2500
train = read.csv("train.csv" , header = F , nrows = train_rows )
test = read.csv( " test.csv " , header = F , nrow= test_rows )
#last column is the label
train$V785 = as.factor(train$V785 )
test$V785 = as.factor(test$V785 )
# remove predictors wth little variability
SD<20 # this parameter was set by tuning on the training set.
# ##
# ## 20 was s o r t o f a g u e s s !
# ##
cut_off = 20
bad_columns = which ( apply( train[ , - ncol( train ) ] , 2 , sd ) < cut_off )
length( bad_columns )
train = train[ ,-bad_columns ]
test = test[,-bad_columns]
# Train and test with SVM
library(e1071)
# tune
set.seed(110)
system.time ( {
tune_svm = tune( svm , V785 ~ . , data = train , kernel = " polynomial " , degree =3 ,
ranges = list ( cost = c(1,5,10,1000 ) , gamma = c(0.0001, 0.001,0.01,1)),
tunecontrol = tune.control(cross=5))
} )
tune_svm
# Create Final Model withh parameters
svm_final = svm( V785 ~ . , data = train , cost = tune_svm$best.parameters$cost , kernel = "polynomial " , degree =3 ,
gamma = tune_svm$best.parameters$gamma)
svm_y_final = predict( svm_final , newdata = test )
train_rows = 5000
test_rows = 2500
train = read.csv("train.csv" , header = F , nrows = train_rows )
test = read.csv( "test.csv" , header = F , nrow= test_rows )
#last column is the label
train$V785 = as.factor(train$V785 )
test$V785 = as.factor(test$V785 )
test$V785 = as.factor(test$V785 )
test&V785
names(test)
SD<20 # this parameter was set by tuning on the training set.
# ##
# ## 20 was s o r t o f a g u e s s !
# ##
cut_off = 20
bad_columns = which ( apply( train[ , - ncol( train ) ] , 2 , sd ) < cut_off )
length( bad_columns )
train = train[ ,-bad_columns ]
test = test[,-bad_columns]
length(train)
length(test)
names(train)
library(e1071)
# tune
set.seed(110)
system.time ( {
tune_svm = tune( svm , V785 ~ . , data = train , kernel = " polynomial " , degree =3 ,
ranges = list ( cost = c(1,5,10,1000 ) , gamma = c(0.0001, 0.001,0.01,1)),
tunecontrol = tune.control(cross=5))
} )
tune_svm
library(e1071)
# tune
set.seed(110)
system.time ( {
tune_svm = tune( svm , V785 ~ . , data = train , kernel = " polynomial " , degree =3 ,
ranges = list ( cost = c(1,5,10,1000 ) , gamma = c(0.0001, 0.001,0.01,1)),
tunecontrol = tune.control(cross=5))
} )
tune_svm
